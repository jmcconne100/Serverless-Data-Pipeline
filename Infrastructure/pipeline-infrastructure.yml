AWSTemplateFormatVersion: '2010-09-09'
Description: Merged CloudFormation template for Pipeline Infrastructure and Redshift

Parameters:
  VPCName:
    Type: String
    Default: "RedshiftVPC"

  RedshiftClusterName:
    Type: String
    Default: "my-redshift-cluster"

  RedshiftDatabaseName:
    Type: String
    Default: "mydatabase"

  RedshiftMasterUsername:
    Type: String
    Default: "admin"
    NoEcho: true

  RedshiftMasterPassword:
    Type: String
    NoEcho: true
    MinLength: 8
    MaxLength: 64
    AllowedPattern: "^[a-zA-Z0-9!@#$%^&*()_+=-]*$"
    Description: "Redshift master password (must be 8-64 characters, no spaces)"

  NodeType:
    Type: String
    Default: "dc2.large"

  NumberOfNodes:
    Type: Number
    Default: 2
    MinValue: 1
    MaxValue: 10

Resources:
  # VPC for Redshift
  RedshiftVPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsSupport: true
      EnableDnsHostnames: true
      Tags:
        - Key: Name
          Value: !Ref VPCName

  # Internet Gateway
  RedshiftInternetGateway:
    Type: AWS::EC2::InternetGateway

  # Attach Internet Gateway to VPC
  RedshiftVPCGatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref RedshiftVPC
      InternetGatewayId: !Ref RedshiftInternetGateway

  # Public Subnets
  RedshiftPublicSubnet1A:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref RedshiftVPC
      CidrBlock: 10.0.1.0/24
      AvailabilityZone: us-west-1a
      MapPublicIpOnLaunch: true

  RedshiftPublicSubnet1C:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref RedshiftVPC
      CidrBlock: 10.0.2.0/24
      AvailabilityZone: us-west-1c
      MapPublicIpOnLaunch: true

  # Security Group for Redshift
  RedshiftSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow Redshift access
      VpcId: !Ref RedshiftVPC
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 5439
          ToPort: 5439
          CidrIp: 0.0.0.0/0  # Modify for security

  # Subnet Group for Redshift
  RedshiftSubnetGroup:
    Type: AWS::Redshift::ClusterSubnetGroup
    Properties:
      Description: "Subnet Group for Redshift Cluster"
      SubnetIds:
        - !Ref RedshiftPublicSubnet1A
        - !Ref RedshiftPublicSubnet1C

  GlueCrawler:
    Type: AWS::Glue::Crawler
    Properties:
      Name: "MyGlueCrawler"
      Role: !GetAtt GlueJobRole.Arn  # Uses the existing IAM role for Glue jobs
      DatabaseName: "glue_hello-world-database"  # Replace with your Glue database
      Targets:
        S3Targets:
          - Path: "s3://jon-data-pipeline-bucket/input-data/"  # S3 folder to scan
      TablePrefix: "glue_"  # Prefix for created tables
      SchemaChangePolicy:
        UpdateBehavior: "UPDATE_IN_DATABASE"
        DeleteBehavior: "DEPRECATE_IN_DATABASE"
      RecrawlPolicy:
        RecrawlBehavior: "CRAWL_EVERYTHING"  # Always scan the full dataset
      Configuration: "{\"Version\":1.0,\"Grouping\":{\"TableGroupingPolicy\":\"CombineCompatibleSchemas\"}}"

  # IAM Role for Glue Job
  GlueJobRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "GlueETLHelloWorldRole-${AWS::Region}"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: glue.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: GlueETLHelloWorldPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:GetObject
                  - s3:ListBucket
                Resource:
                  - !Sub "arn:aws:s3:::jon-scripts-bucket"
                  - !Sub "arn:aws:s3:::jon-scripts-bucket/*"
                  - !Sub "arn:aws:s3:::${DataBucket}"
                  - !Sub "arn:aws:s3:::${DataBucket}/*"
              - Effect: Allow
                Action:
                  - glue:CreateJob
                  - glue:StartJobRun
                  - glue:GetJobRun
                  - glue:GetJobRuns
                  - glue:GetJobs
                  - glue:BatchStopJobRun
                Resource: "*"
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "*"
              - Effect: Allow
                Action:
                  - kms:Encrypt
                  - kms:Decrypt
                  - kms:GenerateDataKey
                Resource: !GetAtt MyKMSKey.Arn

  # CloudWatch Log Group for Glue Job
  GlueLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub "/aws-glue/jobs/${AWS::StackName}"
      RetentionInDays: 7

  # AWS Glue Job
  GlueJob:
    Type: AWS::Glue::Job
    Properties:
      Name: "GlueHelloWorldJob"
      Role: !GetAtt GlueJobRole.Arn
      Command:
        Name: "glueetl"
        ScriptLocation: "s3://jon-scripts-bucket/glue-hello-world.py"
        PythonVersion: "3"
      GlueVersion: "3.0"
      MaxCapacity: 2.0
      ExecutionProperty:
        MaxConcurrentRuns: 1
      DefaultArguments:
        "--job-bookmark-option": "job-bookmark-disable"
        "--TempDir": "s3://jon-scripts-bucket/temp/"
        "--enable-continuous-cloudwatch-log": "true"
        "--enable-metrics": "true"

  # KMS Key for encrypting S3 bucket data
  MyKMSKey:
    Type: AWS::KMS::Key
    Properties:
      Description: "KMS Key for encrypting S3 bucket data"
      KeyPolicy:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal: 
              AWS: !Sub arn:aws:iam::${AWS::AccountId}:root
            Action: "kms:*"
            Resource: "*"

  # Log bucket for CloudTrail logs
  LogBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub 'jon-data-pipeline-cloudtrail-logs-bucket'
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true

  LogBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref LogBucket
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          # Allow CloudTrail to write logs
          - Effect: Allow
            Principal:
              Service: cloudtrail.amazonaws.com
            Action: "s3:PutObject"
            Resource: !Sub "arn:aws:s3:::${LogBucket}/AWSLogs/${AWS::AccountId}/*"
            Condition:
              StringEquals:
                aws:SourceAccount: !Sub "${AWS::AccountId}"
              ArnLike:
                aws:SourceArn: !Sub "arn:aws:cloudtrail:${AWS::Region}:${AWS::AccountId}:trail/MyCloudTrail"

          # Allow CloudTrail to get bucket ACL
          - Effect: Allow
            Principal:
              Service: cloudtrail.amazonaws.com
            Action: "s3:GetBucketAcl"
            Resource: !Sub "arn:aws:s3:::${LogBucket}"
            Condition:
              StringEquals:
                aws:SourceAccount: !Sub "${AWS::AccountId}"

  # General data bucket with KMS encryption and logging
  DataBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub 'jon-data-pipeline-bucket'
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: "aws:kms"
              KMSMasterKeyID: !Ref MyKMSKey
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LoggingConfiguration:
        DestinationBucketName: !Ref LogBucket
        LogFilePrefix: "DataBucketLogs/"
      VersioningConfiguration:
        Status: Enabled

  # CloudTrail logging setup
  CloudTrail:
    Type: AWS::CloudTrail::Trail
    DependsOn: LogBucketPolicy  # Ensures policy is in place before CloudTrail starts
    Properties:
      TrailName: MyCloudTrail
      S3BucketName: !Ref LogBucket
      IncludeGlobalServiceEvents: true
      IsLogging: true
      IsMultiRegionTrail: true
      EnableLogFileValidation: true

  # IAM Group for CloudTrail Service and Log Bucket Access
  CloudTrailAccessGroup:
    Type: AWS::IAM::Group
    Properties:
      GroupName: CloudTrailAccessGroup

  # IAM Policy for CloudTrail Service and Log Bucket Access
  CloudTrailAccessPolicy:
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: CloudTrailAccessPolicy
      Groups:
        - !Ref CloudTrailAccessGroup
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action:
              - "cloudtrail:DescribeTrails"
              - "cloudtrail:GetTrailStatus"
              - "cloudtrail:ListTrails"
              - "cloudtrail:StartLogging"
              - "cloudtrail:StopLogging"
            Resource: "*"
          - Effect: Allow
            Action:
              - "s3:GetObject"
              - "s3:ListBucket"
            Resource:
              - !Sub "arn:aws:s3:::${LogBucket}"
              - !Sub "arn:aws:s3:::${LogBucket}/AWSLogs/${AWS::AccountId}/*"

  # IAM Group for S3 and KMS Access
  S3KMSAccessGroup:
    Type: AWS::IAM::Group
    Properties:
      GroupName: "S3AccessGroup"

  # IAM Policy for S3 and KMS Access
  S3KMSAccessPolicy:
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: "S3KMSAccessPolicy"
      Groups: 
        - !Ref S3KMSAccessGroup
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Action:
              - "s3:GetObject"
              - "s3:PutObject"
              - "s3:ListBucket"
            Resource: 
              - !Sub "arn:aws:s3:::${DataBucket}"
              - !Sub "arn:aws:s3:::${DataBucket}/*"
          - Effect: Allow
            Action:
              - "kms:Decrypt"
              - "kms:Encrypt"
            Resource: !GetAtt MyKMSKey.Arn

  # Lambda Execution Role with KMS permissions
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: LambdaS3KMSExecutionRole
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: "sts:AssumeRole"
      Policies:
        - PolicyName: LambdaS3KMSAccessPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - "s3:PutObject"
                  - "s3:ListBucket"
                Resource:
                  - !Sub "arn:aws:s3:::${DataBucket}"
                  - !Sub "arn:aws:s3:::${DataBucket}/*"
              - Effect: Allow
                Action:
                  - "kms:Encrypt"
                  - "kms:Decrypt"
                  - "kms:GenerateDataKey"
                Resource: !GetAtt MyKMSKey.Arn
              - Effect: Allow
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: "*"

  # Lambda Function (Inline Code)
  HelloWorldLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: HelloWorldLambda
      Runtime: python3.9
      Role: !GetAtt LambdaExecutionRole.Arn
      Handler: index.lambda_handler
      Timeout: 30
      MemorySize: 128
      Environment:
        Variables:
          DATA_BUCKET: !Ref DataBucket
      Code:
        ZipFile: |
          import boto3
          import os

          def lambda_handler(event, context):
              s3 = boto3.client('s3')
              bucket_name = os.environ['DATA_BUCKET']
              
              file_name = "hello_world.txt"
              file_content = "Hello from Lambda!"

              try:
                  s3.put_object(Bucket=bucket_name, Key=file_name, Body=file_content)
                  return {
                      'statusCode': 200,
                      'body': f'Successfully wrote {file_name} to {bucket_name}'
                  }
              except Exception as e:
                  return {
                      'statusCode': 500,
                      'body': str(e)
                  }

  # IAM Role for Redshift to access S3 and KMS
  RedshiftS3AccessRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${RedshiftClusterName}-S3AccessRole"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: redshift.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: S3RedshiftPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - "s3:ListBucket"
                  - "s3:GetObject"
                  - "s3:PutObject"
                Resource:
                  - !Sub "arn:aws:s3:::jon-data-pipeline-bucket"
                  - !Sub "arn:aws:s3:::jon-data-pipeline-bucket/*"
              - Effect: Allow
                Action:
                  - "kms:Decrypt"
                  - "kms:Encrypt"
                Resource: !GetAtt MyKMSKey.Arn

  # Secrets Manager for Redshift Credentials
  RedshiftSecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      Name: !Sub "${RedshiftClusterName}-credentials"
      Description: "Credentials for Redshift Cluster"
      SecretString:
        !Sub |
          {
            "username": "${RedshiftMasterUsername}",
            "password": "${RedshiftMasterPassword}"
          }

  # Redshift Cluster
  RedshiftCluster:
    Type: AWS::Redshift::Cluster
    Properties:
      ClusterIdentifier: !Ref RedshiftClusterName
      ClusterType: multi-node
      NodeType: !Ref NodeType
      NumberOfNodes: !Ref NumberOfNodes
      MasterUsername: !Sub "{{resolve:secretsmanager:${RedshiftSecret}:SecretString:username}}"
      MasterUserPassword: !Sub "{{resolve:secretsmanager:${RedshiftSecret}:SecretString:password}}"
      DBName: !Ref RedshiftDatabaseName
      ClusterSubnetGroupName: !Ref RedshiftSubnetGroup
      VpcSecurityGroupIds:
        - !Ref RedshiftSecurityGroup
      PubliclyAccessible: true
      Encrypted: true
      IamRoles:
        - !GetAtt RedshiftS3AccessRole.Arn

Outputs:
  RedshiftIAMRole:
    Description: "IAM Role for Redshift to access S3"
    Value: !Ref RedshiftS3AccessRole

  RedshiftClusterEndpoint:
    Description: "Redshift Cluster Endpoint"
    Value: !Sub "${RedshiftCluster.Endpoint.Address}"

  KMSKeyArn:
    Description: "ARN of the KMS Key for encryption"
    Value: !GetAtt MyKMSKey.Arn

  LogBucketName:
    Description: Name of the S3 bucket for CloudTrail logs
    Value: !Ref LogBucket

  DataBucketName:
    Description: Name of the additional S3 bucket with KMS encryption
    Value: !Ref DataBucket

  CloudTrailAccessGroup:
    Description: IAM Group with CloudTrail and LogBucket Access
    Value: !Ref CloudTrailAccessGroup

  S3KMSAccessGroup:
    Description: IAM Group with S3 and KMS Access
    Value: !Ref S3KMSAccessGroup

  LambdaFunctionName:
    Description: Name of the Lambda function that writes Hello World to S3
    Value: !Ref HelloWorldLambda

  LambdaExecutionRole:
    Description: IAM Role for Lambda execution
    Value: !GetAtt LambdaExecutionRole.Arn

  GlueJobName:
    Description: "AWS Glue Job Name"
    Value: !Ref GlueJob

  CloudWatchLogGroup:
    Description: "CloudWatch Log Group for Glue Job"
    Value: !Ref GlueLogGroup
